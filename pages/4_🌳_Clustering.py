"""
P√°gina Streamlit - Requerimiento 4: Clustering Jer√°rquico
"""

import streamlit as st
import sys
import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from scipy.cluster.hierarchy import linkage, dendrogram, cophenet, fcluster
from scipy.spatial.distance import pdist
import matplotlib.pyplot as plt

# Agregar el directorio ra√≠z al path
BASE_DIR = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(BASE_DIR))

st.title("üå≥ Requerimiento 4: Clustering Jer√°rquico")

st.markdown("""
### Descripci√≥n
Este m√≥dulo implementa **3 algoritmos de agrupamiento jer√°rquico**:
1. **Single Linkage** - Enlace simple (m√≠nima distancia)
2. **Complete Linkage** - Enlace completo (m√°xima distancia)
3. **Average Linkage** - Enlace promedio (distancia promedio)

Cada algoritmo genera un dendrograma que representa la similitud entre abstracts cient√≠ficos.
""")

st.markdown("---")

# Cargar datos
ABSTRACTS_CSV = BASE_DIR / "Requerimiento3" / "DatosProcesados" / "abstracts_limpios.csv"
BIB_PATH = BASE_DIR / "Requerimiento1" / "ArchivosFiltrados" / "articulosOptimos_limpio.bib"

if not ABSTRACTS_CSV.exists():
    st.warning("‚ö†Ô∏è No se encontr√≥ el archivo de abstracts procesados.")
    st.info("üí° Ejecuta el Requerimiento 3 primero para procesar los abstracts.")
    
    # Opci√≥n alternativa: procesar desde BibTeX
    if BIB_PATH.exists():
        st.markdown("### Procesar desde BibTeX")
        if st.button("Procesar abstracts ahora"):
            with st.spinner("Procesando abstracts..."):
                # Aqu√≠ ir√≠a la l√≥gica de procesamiento
                st.info("Esta funcionalidad requiere ejecutar el script de preparaci√≥n de datos.")
    st.stop()

# Cargar datos
@st.cache_data
def cargar_datos():
    """Carga los abstracts procesados."""
    try:
        df = pd.read_csv(ABSTRACTS_CSV)
        if 'abstract_limpio' not in df.columns:
            st.error("El archivo CSV no tiene la columna 'abstract_limpio'")
            return None
        
        df = df.dropna(subset=['abstract_limpio']).drop_duplicates(subset=['abstract_limpio']).reset_index(drop=True)
        return df
    except Exception as e:
        st.error(f"Error al cargar datos: {e}")
        return None

df = cargar_datos()

if df is None:
    st.stop()

st.success(f"‚úÖ Se cargaron {len(df)} abstracts procesados")

# Configuraci√≥n
st.subheader("‚öôÔ∏è Configuraci√≥n")

max_abstracts = st.slider(
    "N√∫mero m√°ximo de abstracts a analizar",
    min_value=50,
    max_value=min(500, len(df)),
    value=min(200, len(df)),
    step=50
)

metodos = st.multiselect(
    "Seleccionar m√©todos de clustering",
    ['single', 'complete', 'average'],
    default=['single', 'complete', 'average']
)

# Procesar
if st.button("üå≥ Generar Dendrogramas", type="primary"):
    with st.spinner("Procesando clustering..."):
        # Tomar muestra
        df_sample = df.head(max_abstracts).copy()
        abstracts = df_sample['abstract_limpio'].tolist()
        
        # Vectorizar
        st.info("Vectorizando abstracts con TF-IDF...")
        vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
        X = vectorizer.fit_transform(abstracts).toarray()
        
        # Eliminar filas con vectores cero
        filas_validas = np.any(X != 0, axis=1)
        X = X[filas_validas]
        df_sample = df_sample[filas_validas].reset_index(drop=True)
        
        st.success(f"‚úÖ {len(df_sample)} abstracts v√°lidos para clustering")
        
        # Calcular distancias
        st.info("Calculando matriz de distancias...")
        dist_matrix = pdist(X, 'cosine')
        
        resultados_cophenetic = []
        
        # Generar dendrogramas
        for metodo in metodos:
            st.info(f"Procesando m√©todo: {metodo}...")
            
            try:
                # Aplicar clustering
                Z = linkage(dist_matrix, method=metodo)
                coph_corr, _ = cophenet(Z, dist_matrix)
                resultados_cophenetic.append({
                    "M√©todo": metodo.upper(),
                    "Correlaci√≥n Cophen√©tica": f"{coph_corr:.4f}",
                    "Valor": coph_corr
                })
                
                # Generar dendrograma
                fig, ax = plt.subplots(figsize=(14, 8))
                dendrogram(
                    Z,
                    leaf_rotation=90,
                    leaf_font_size=8,
                    color_threshold=0.7,
                    above_threshold_color='gray',
                    truncate_mode='level',
                    p=10
                )
                ax.set_title(f"Dendrograma - {metodo.upper()} Linkage\nCorrelaci√≥n Cophen√©tica: {coph_corr:.4f}", 
                           fontsize=14, fontweight='bold')
                ax.set_xlabel("Abstracts", fontsize=12)
                ax.set_ylabel("Distancia", fontsize=12)
                plt.tight_layout()
                
                st.pyplot(fig)
                plt.close()
                
            except Exception as e:
                st.error(f"Error al procesar m√©todo {metodo}: {e}")
        
        # Mostrar comparaci√≥n
        if resultados_cophenetic:
            st.markdown("---")
            st.subheader("üìä Comparaci√≥n de M√©todos")
            
            df_comparacion = pd.DataFrame(resultados_cophenetic)
            df_comparacion = df_comparacion.sort_values("Valor", ascending=False)
            
            st.dataframe(df_comparacion[["M√©todo", "Correlaci√≥n Cophen√©tica"]], use_container_width=True)
            
            # Gr√°fico de comparaci√≥n
            fig, ax = plt.subplots(figsize=(10, 6))
            metodos_nombres = df_comparacion["M√©todo"].tolist()
            valores = df_comparacion["Valor"].tolist()
            bars = ax.bar(metodos_nombres, valores, color=['#1f77b4', '#ff7f0e', '#2ca02c'])
            ax.set_ylabel("Correlaci√≥n Cophen√©tica", fontsize=12)
            ax.set_title("Comparaci√≥n de M√©todos de Clustering", fontsize=14, fontweight='bold')
            ax.set_ylim(0, 1)
            
            # Agregar valores en las barras
            for bar, val in zip(bars, valores):
                ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                       f'{val:.4f}', ha='center', va='bottom', fontsize=10)
            
            plt.tight_layout()
            st.pyplot(fig)
            
            # Mejor m√©todo
            mejor_metodo = df_comparacion.iloc[0]
            st.success(f"üèÜ Mejor m√©todo: **{mejor_metodo['M√©todo']}** con correlaci√≥n cophen√©tica de **{mejor_metodo['Correlaci√≥n Cophen√©tica']}**")
            
            st.info("""
            üí° **Interpretaci√≥n**: 
            - La correlaci√≥n cophen√©tica mide qu√© tan bien el dendrograma preserva las distancias originales
            - Un valor m√°s alto indica mejor preservaci√≥n de la estructura de datos
            - El mejor m√©todo es el que tiene la mayor correlaci√≥n cophen√©tica
            """)

st.markdown("---")

# Informaci√≥n adicional
with st.expander("üìñ Explicaci√≥n de los M√©todos"):
    st.markdown("""
    **Single Linkage (Enlace Simple)**:
    - Usa la m√≠nima distancia entre clusters
    - Tiende a crear clusters largos y delgados
    - Sensible a outliers
    
    **Complete Linkage (Enlace Completo)**:
    - Usa la m√°xima distancia entre clusters
    - Tiende a crear clusters compactos y esf√©ricos
    - Menos sensible a outliers
    
    **Average Linkage (Enlace Promedio)**:
    - Usa la distancia promedio entre clusters
    - Balance entre single y complete
    - Generalmente produce resultados equilibrados
    """)

